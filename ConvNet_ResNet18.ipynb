{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ConvNet.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "CFEyrp_mYmIO",
        "ZX0XLJDjkqX_",
        "3yEtGFpwdYx1",
        "K7VpSLb22POJ"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jwang44/upgraded-octo-chainsaw/blob/main/ConvNet_ResNet18.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dOxAvsuIul3",
        "outputId": "49c631df-158f-4372-cd61-43f6d21b91ce"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tj7sHHnv5fa",
        "outputId": "ac2dde2f-6bb6-480e-c9b9-2d84b9dd17f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd '/content/drive/MyDrive/imageunderstanding'\n",
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/imageunderstanding\n",
            "ExampleSubmissionRandom.csv  PRED_RESULT.csv  Train_labels.csv\n",
            "Load_data.ipynb\t\t     Test.pkl\t      Train.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqRELpG1DsZq",
        "outputId": "50d5756d-0163-497a-ef46-0673b538bf5a"
      },
      "source": [
        "%cd '/content/drive/MyDrive/551 A3'\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/551 A3\n",
            " ExampleSubmissionRandom.csv   Test.pkl\t\t       Train_labels.csv\n",
            " LoadData.ipynb\t\t      'Train_labels (1).csv'   Train.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1-Hfwf3lrw4"
      },
      "source": [
        "TRAIN_DATA_PATH = \"Train.pkl\"\n",
        "TRAIN_LABEL_PATH = \"Train_labels.csv\"\n",
        "TEST_DATA_PATH = \"Test.pkl\"\n",
        "CSV_OUTPUT_PATH = \"PRED_RESULT.csv\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XS2MS7nHzIN"
      },
      "source": [
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from PIL import Image\n",
        "import torch\n",
        "import pandas as pd"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBXdYCpunCp2",
        "outputId": "1d606df3-f652-49fc-8b8a-28cbb1454595"
      },
      "source": [
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "DEVICE"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zppkOjQwVjy2"
      },
      "source": [
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2Vm3wY_K3DA"
      },
      "source": [
        "## Dataset Class / Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bydOoypc5SAM"
      },
      "source": [
        "IMG_SIZE = (224, 224)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMnXBwXMCqd5"
      },
      "source": [
        "# Transforms are common image transformations. They can be chained together using Compose.\n",
        "# Here we normalize images img=(img-0.5)/0.5\n",
        "img_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    # transforms.Normalize([0.5], [0.5]),\n",
        "    transforms.Resize(IMG_SIZE)  \n",
        "    # transforms.RandomRotation(10, resample=PIL.Image.BILINEAR)\n",
        "    # transforms.ColorJitter(brightness=0, contrast=0, saturation=0, hue=0)\n",
        "    # transforms.RandomAffine(degrees, translate=None, scale=None, shear=None, interpolation=<InterpolationMode.NEAREST: 'nearest'>, fill=0, fillcolor=None, resample=None)\n",
        "])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CY0SndE2qcmb"
      },
      "source": [
        "# img_file: the pickle file containing the images\n",
        "# label_file: the .csv file containing the labels\n",
        "# transform: We use it for normalizing images (see above)\n",
        "# idx: This is a binary vector that is useful for creating training and validation set.\n",
        "# It return only samples where idx is True\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, img_file, label_file, transform=None, idx = None):\n",
        "        self.data = pickle.load( open( img_file, 'rb' ), encoding='bytes')\n",
        "        self.targets = np.genfromtxt(label_file, delimiter=',', skip_header=1, usecols=1) #[:,1:]\n",
        "        if idx is not None:\n",
        "          self.targets = self.targets[idx]\n",
        "          self.data = self.data[idx]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.targets)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img, target = self.data[index].squeeze(), int(self.targets[index])\n",
        "        img = Image.fromarray((img*255).astype('uint8'), mode='L')\n",
        "        if self.transform is not None:\n",
        "           img = self.transform(img)\n",
        "        return img, target"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3b-QvEvqNE3"
      },
      "source": [
        "Get loader for all train data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74kV_DwkqizL"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "dataset = MyDataset(TRAIN_DATA_PATH, TRAIN_LABEL_PATH,transform=img_transform, idx=None)\n",
        "# dataloader for all data\n",
        "data_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZNiErb-pbPt"
      },
      "source": [
        "Get loaders for train/val data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05SXSXBRW4DX"
      },
      "source": [
        "VAL_SPLIT = 0.15\n",
        "shuffle = True\n",
        "\n",
        "# Creating indices for train and val split:\n",
        "dataset_size = len(dataset)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(VAL_SPLIT * dataset_size))\n",
        "if shuffle:\n",
        "  # set random seed so that we get the same split everytime\n",
        "  np.random.seed(0)\n",
        "  np.random.shuffle(indices)\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "train_dataset = MyDataset(TRAIN_DATA_PATH, TRAIN_LABEL_PATH,transform=img_transform, idx=train_indices)\n",
        "val_dataset = MyDataset(TRAIN_DATA_PATH, TRAIN_LABEL_PATH,transform=img_transform, idx=val_indices)\n",
        "\n",
        "# separate loaders for train and val data\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFEyrp_mYmIO"
      },
      "source": [
        "## Test Dataset / Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1d3LIGlYrDK"
      },
      "source": [
        "class MyTestSet(Dataset):\n",
        "  def __init__(self, img_file, transform=None):\n",
        "    self.data = pickle.load( open(img_file, 'rb' ), encoding='bytes')\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    # return self.data.shape[0]\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    img = self.data[index].squeeze()\n",
        "    img = Image.fromarray((img*255).astype('uint8'), mode='L')\n",
        "    if self.transform is not None:\n",
        "      img = self.transform(img)\n",
        "    return img"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fk5z7LRha2Uc"
      },
      "source": [
        "test_dataset = MyTestSet(TEST_DATA_PATH,transform=img_transform)\n",
        "# dataloader for test data\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdvC0-OfRnQV"
      },
      "source": [
        "## ResNet18"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFVSRS6gs8t7"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "import torchvision.models as models"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeVwuJHatdb7"
      },
      "source": [
        "Let's train these. But first, create the network, the optimizer and some lists for logging the training process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGj4HgAEMsxA"
      },
      "source": [
        "### alexnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vx68ZfoSGgZy"
      },
      "source": [
        "# model = models.alexnet(pretrained=False)\n",
        "# model.features[0] = nn.Conv2d(1, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
        "# model.classifier[6] = nn.Linear(4096, 10)\n",
        "# model = model.to(DEVICE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ci11eU_mKnkX"
      },
      "source": [
        "### resnet18"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfN0avQP398k"
      },
      "source": [
        "model = models.resnet18(pretrained=False)\n",
        "model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "model.fc = nn.Linear(in_features=512, out_features=10, bias=True)\n",
        "model = model.to(DEVICE)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Kcb2ohYKrRk"
      },
      "source": [
        "### resnet34"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-Lb5h6MJmXv"
      },
      "source": [
        "model = models.resnet34(pretrained=False)\n",
        "model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "model.fc = nn.Linear(in_features=512, out_features=10, bias=True)\n",
        "model = model.to(DEVICE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFDcK-NeKvm4"
      },
      "source": [
        "### optimizer & initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJqfMWSFIztX"
      },
      "source": [
        "# optimizer = optim.SGD(tutor_model.parameters(), lr=0.01, momentum=0.5)\n",
        "# optimizer = optim.SGD(tutor_model.parameters(), lr=1, momentum=0.5)\n",
        "# optimizer = optim.Adam(model.parameters())\n",
        "optimizer = optim.RMSprop(model.parameters())\n",
        "\n",
        "train_losses = []\n",
        "train_counter = []\n",
        "val_losses = []\n",
        "val_counter = [i*len(train_loader.dataset) for i in range(3)]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ck4yNKs46Q1Y"
      },
      "source": [
        "### Train and test function, used many times"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ps3KWsvtlSS"
      },
      "source": [
        "def train(epoch, model, loader):\n",
        "  model.train()\n",
        "  for batch_idx, (data, target) in enumerate(loader):\n",
        "    optimizer.zero_grad()\n",
        "    data = data.to(DEVICE)\n",
        "    # print(data.shape)\n",
        "    target = target.to(DEVICE)\n",
        "    output = model(data)\n",
        "    # print(output.shape)\n",
        "    # target = torch.argmax(target, dim=1) # convert from 1-hot to 1D\n",
        "    loss = F.cross_entropy(output, target) #negative log likelihood loss\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if batch_idx % 200 == 0:\n",
        "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "        epoch, batch_idx * len(data), len(loader.dataset),\n",
        "        100. * batch_idx / len(loader), loss.item()))\n",
        "      train_losses.append(loss.item())\n",
        "      train_counter.append(\n",
        "        (batch_idx*64) + ((epoch-1)*len(loader.dataset)))\n",
        "      torch.save(model.state_dict(), '/model.pth')\n",
        "      torch.save(optimizer.state_dict(), '/optimizer.pth')\n",
        "\n",
        "def val(model, loader):\n",
        "  model.eval()\n",
        "  val_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for data, target in loader:\n",
        "      data = data.to(DEVICE)\n",
        "      target = target.to(DEVICE)\n",
        "      output = model(data)\n",
        "      val_loss += F.cross_entropy(output, target, size_average=False).item()\n",
        "      pred = output.data.max(1, keepdim=True)[1]\n",
        "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
        "  val_loss /= len(loader.dataset)\n",
        "  val_losses.append(val_loss)\n",
        "  print('Val set: Epoch: {}, Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
        "    epoch, val_loss, correct, len(loader.dataset),\n",
        "    100. * correct / len(loader.dataset)))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaaA04yUtj1T"
      },
      "source": [
        "Train the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCgK_yOvtrjz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "155156b6-b623-4f7c-afdd-851ae86d7f79"
      },
      "source": [
        "for epoch in range(1, 20):\n",
        "  train(epoch, model, train_loader)\n",
        "  val(model, val_loader)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/51000 (0%)]\tLoss: 2.501408\n",
            "Train Epoch: 1 [25600/51000 (50%)]\tLoss: 1.768204\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val set: Epoch: 1, Avg. loss: 0.6560, Accuracy: 7334/9000 (81%)\n",
            "Train Epoch: 2 [0/51000 (0%)]\tLoss: 0.399630\n",
            "Train Epoch: 2 [25600/51000 (50%)]\tLoss: 0.314973\n",
            "Val set: Epoch: 2, Avg. loss: 0.3970, Accuracy: 8065/9000 (90%)\n",
            "Train Epoch: 3 [0/51000 (0%)]\tLoss: 0.172807\n",
            "Train Epoch: 3 [25600/51000 (50%)]\tLoss: 0.172641\n",
            "Val set: Epoch: 3, Avg. loss: 0.2522, Accuracy: 8395/9000 (93%)\n",
            "Train Epoch: 4 [0/51000 (0%)]\tLoss: 0.098940\n",
            "Train Epoch: 4 [25600/51000 (50%)]\tLoss: 0.138717\n",
            "Val set: Epoch: 4, Avg. loss: 0.2303, Accuracy: 8490/9000 (94%)\n",
            "Train Epoch: 5 [0/51000 (0%)]\tLoss: 0.153854\n",
            "Train Epoch: 5 [25600/51000 (50%)]\tLoss: 0.062233\n",
            "Val set: Epoch: 5, Avg. loss: 0.1667, Accuracy: 8587/9000 (95%)\n",
            "Train Epoch: 6 [0/51000 (0%)]\tLoss: 0.059971\n",
            "Train Epoch: 6 [25600/51000 (50%)]\tLoss: 0.069005\n",
            "Val set: Epoch: 6, Avg. loss: 0.1588, Accuracy: 8584/9000 (95%)\n",
            "Train Epoch: 7 [0/51000 (0%)]\tLoss: 0.048258\n",
            "Train Epoch: 7 [25600/51000 (50%)]\tLoss: 0.029516\n",
            "Val set: Epoch: 7, Avg. loss: 0.1121, Accuracy: 8741/9000 (97%)\n",
            "Train Epoch: 8 [0/51000 (0%)]\tLoss: 0.038844\n",
            "Train Epoch: 8 [25600/51000 (50%)]\tLoss: 0.086600\n",
            "Val set: Epoch: 8, Avg. loss: 0.1620, Accuracy: 8682/9000 (96%)\n",
            "Train Epoch: 9 [0/51000 (0%)]\tLoss: 0.059277\n",
            "Train Epoch: 9 [25600/51000 (50%)]\tLoss: 0.019425\n",
            "Val set: Epoch: 9, Avg. loss: 0.1266, Accuracy: 8740/9000 (97%)\n",
            "Train Epoch: 10 [0/51000 (0%)]\tLoss: 0.023946\n",
            "Train Epoch: 10 [25600/51000 (50%)]\tLoss: 0.044719\n",
            "Val set: Epoch: 10, Avg. loss: 0.1345, Accuracy: 8734/9000 (97%)\n",
            "Train Epoch: 11 [0/51000 (0%)]\tLoss: 0.009852\n",
            "Train Epoch: 11 [25600/51000 (50%)]\tLoss: 0.028088\n",
            "Val set: Epoch: 11, Avg. loss: 0.2358, Accuracy: 8581/9000 (95%)\n",
            "Train Epoch: 12 [0/51000 (0%)]\tLoss: 0.061072\n",
            "Train Epoch: 12 [25600/51000 (50%)]\tLoss: 0.006670\n",
            "Val set: Epoch: 12, Avg. loss: 0.1892, Accuracy: 8624/9000 (96%)\n",
            "Train Epoch: 13 [0/51000 (0%)]\tLoss: 0.076230\n",
            "Train Epoch: 13 [25600/51000 (50%)]\tLoss: 0.024419\n",
            "Val set: Epoch: 13, Avg. loss: 0.1195, Accuracy: 8767/9000 (97%)\n",
            "Train Epoch: 14 [0/51000 (0%)]\tLoss: 0.026704\n",
            "Train Epoch: 14 [25600/51000 (50%)]\tLoss: 0.017958\n",
            "Val set: Epoch: 14, Avg. loss: 0.1439, Accuracy: 8760/9000 (97%)\n",
            "Train Epoch: 15 [0/51000 (0%)]\tLoss: 0.003262\n",
            "Train Epoch: 15 [25600/51000 (50%)]\tLoss: 0.060690\n",
            "Val set: Epoch: 15, Avg. loss: 0.4059, Accuracy: 8364/9000 (93%)\n",
            "Train Epoch: 16 [0/51000 (0%)]\tLoss: 0.029106\n",
            "Train Epoch: 16 [25600/51000 (50%)]\tLoss: 0.032114\n",
            "Val set: Epoch: 16, Avg. loss: 0.0974, Accuracy: 8817/9000 (98%)\n",
            "Train Epoch: 17 [0/51000 (0%)]\tLoss: 0.007636\n",
            "Train Epoch: 17 [25600/51000 (50%)]\tLoss: 0.002733\n",
            "Val set: Epoch: 17, Avg. loss: 0.0873, Accuracy: 8812/9000 (98%)\n",
            "Train Epoch: 18 [0/51000 (0%)]\tLoss: 0.000740\n",
            "Train Epoch: 18 [25600/51000 (50%)]\tLoss: 0.018287\n",
            "Val set: Epoch: 18, Avg. loss: 0.0941, Accuracy: 8829/9000 (98%)\n",
            "Train Epoch: 19 [0/51000 (0%)]\tLoss: 0.002805\n",
            "Train Epoch: 19 [25600/51000 (50%)]\tLoss: 0.001969\n",
            "Val set: Epoch: 19, Avg. loss: 0.1019, Accuracy: 8817/9000 (98%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcRRKE7MzSEQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "5f35d38e-73ab-4bfc-ba6c-a2e54ecc9b22"
      },
      "source": [
        "fig = plt.figure()\n",
        "plt.plot(train_counter, train_losses, color='skyblue',marker='.')\n",
        "plt.legend(['Train Loss'], loc='upper right')\n",
        "plt.xlabel('number of training examples seen')\n",
        "plt.ylabel('negative log likelihood loss')\n",
        "plt.grid(linestyle='-.')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZX0XLJDjkqX_"
      },
      "source": [
        "## Train on ALL data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZmnWuVmmUCU"
      },
      "source": [
        "full_model = models.resnet34(pretrained=False)\n",
        "full_model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "full_model.fc = nn.Linear(in_features=512, out_features=10, bias=True)\n",
        "full_model = full_model.to(DEVICE)\n",
        "optimizer = optim.RMSprop(full_model.parameters())"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56cCdP5Ektpl",
        "outputId": "4c600c76-56c6-4147-8d89-438f912046b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for epoch in range(1, 19):\n",
        "  train(epoch, full_model, data_loader)\n",
        "  val(full_model, val_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.553793\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yEtGFpwdYx1"
      },
      "source": [
        "## Make predictions on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16kAGX5Hdcur"
      },
      "source": [
        "def predict(model):\n",
        "  pred_test = []\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "      data = data.to(DEVICE)\n",
        "      output = model(data)\n",
        "      pred = output.data.max(1, keepdim=True)[1]\n",
        "      for x in pred:\n",
        "        pred_test.append(x.item())\n",
        "  return pred_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWdnJKhigtM7"
      },
      "source": [
        "pred_test = predict(full_model)\n",
        "print(len(pred_test))\n",
        "df_pred_test = pd.DataFrame({'id': range(10000), 'class': pred_test})\n",
        "df_pred_test.to_csv(CSV_OUTPUT_PATH, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7VpSLb22POJ"
      },
      "source": [
        "## Manually check prediction results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Gp4fBi5iipd"
      },
      "source": [
        "# Read many TEST data and display them, compare with our prediction in CSV\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "imgs = (next(iter(test_loader)))\n",
        "print(imgs.shape)\n",
        "# imgs: [256, 1, 28, 28]\n",
        "imgs = np.squeeze(imgs)\n",
        "# imgs: [256, 28, 28]\n",
        "print(imgs.shape)\n",
        "\n",
        "for i in range(20):\n",
        "  plt.subplot(4,5,i+1)\n",
        "  plt.tight_layout()\n",
        "  plt.imshow(imgs[i], cmap='gray', interpolation='bicubic')\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIDJM1PnADIt"
      },
      "source": [
        "## Deeper（doesn't work）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vcqne0XZLcYf"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdDmYca6CmXP"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MWRg9T5AFNR"
      },
      "source": [
        "class MyModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MyModel, self).__init__()\n",
        "    \n",
        "    self.model = nn.Sequential(\n",
        "      nn.Conv2d(1, 16, kernel_size=3), nn.ReLU(), # 26*26\n",
        "      nn.Conv2d(16, 16, kernel_size=3), nn.ReLU(), # 24*24\n",
        "      # nn.MaxPool2d(2,2), # 13*13\n",
        "\n",
        "      nn.Conv2d(16, 32, kernel_size=3), nn.ReLU(),  # 22*22\n",
        "      nn.Conv2d(32, 32, kernel_size=3), nn.ReLU(),  # 20*20\n",
        "      # nn.MaxPool2d(2,2),  # 6*6\n",
        "\n",
        "      nn.Conv2d(32, 64, kernel_size=3), nn.ReLU(),  # 18*18\n",
        "      nn.Conv2d(64, 64, kernel_size=3), nn.ReLU(),  # 16*16\n",
        "      # nn.MaxPool2d(2,2),  # 2*2\n",
        "\n",
        "      nn.Conv2d(64, 128, kernel_size=3), nn.ReLU(), # 14*14\n",
        "      nn.Conv2d(128, 128, kernel_size=3), nn.ReLU(),  # 12*12\n",
        "      # nn.MaxPool2d(2,2),\n",
        "\n",
        "      nn.Conv2d(128, 256, kernel_size=3), nn.ReLU(),  # 10*10\n",
        "      nn.Conv2d(256, 256, kernel_size=3), nn.ReLU(),  # 8*8\n",
        "      nn.MaxPool2d(2,2),  # 4*4\n",
        "\n",
        "    )\n",
        "    \n",
        "    self.classifier = nn.Sequential(\n",
        "      nn.Flatten(),\n",
        "      nn.Dropout(0.25),\n",
        "      # nn.Linear(4096, 256),\n",
        "      nn.Linear(4096, 256),\n",
        "      nn.ReLU(),\n",
        "\n",
        "      nn.Dropout(0.5),\n",
        "      nn.Linear(256, 10),\n",
        "      nn.Softmax(dim=1)\n",
        "    )\n",
        "    \n",
        "  def forward(self, x):\n",
        "    f = self.model(x)\n",
        "    y_pred = self.classifier(f)\n",
        "    return y_pred\n",
        "\n",
        "network = MyModel()\n",
        "# summary(model, (3,256,256))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7daPmiD_EJ53"
      },
      "source": [
        "optimizer = optim.Adam(network.parameters())\n",
        "\n",
        "train_losses = []\n",
        "train_counter = []\n",
        "test_losses = []\n",
        "test_counter = [i*len(train_loader.dataset) for i in range(3)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tv66liBRDHL9"
      },
      "source": [
        "def train(epoch):\n",
        "  network.train()\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    optimizer.zero_grad()\n",
        "    output = network(data)\n",
        "\n",
        "    loss = F.nll_loss(output, target) #negative log likelihood loss\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if batch_idx % 20 == 0:\n",
        "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "        100. * batch_idx / len(train_loader), loss.item()))\n",
        "      train_losses.append(loss.item())\n",
        "      train_counter.append(\n",
        "        (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
        "\n",
        "def test():\n",
        "  network.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for data, target in val_loader:\n",
        "      output = network(data)\n",
        "      # this line is added to convert labels to LongTensor\n",
        "      # target = target.type(torch.LongTensor)\n",
        "      # target = torch.argmax(target, dim=1) # convert from 1-hot to 1D\n",
        "\n",
        "      test_loss += F.nll_loss(output, target, size_average=False).item()\n",
        "      pred = output.data.max(1, keepdim=True)[1]\n",
        "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
        "  test_loss /= len(val_loader.dataset)\n",
        "  test_losses.append(test_loss)\n",
        "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "    test_loss, correct, len(val_loader.dataset),\n",
        "    100. * correct / len(val_loader.dataset)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30Rz0VM-FKN5"
      },
      "source": [
        "for epoch in range(1, 4):\n",
        "  train(epoch)\n",
        "  test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJ1U0lhpHojX"
      },
      "source": [
        "print(torch.cuda.is_available())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3I5ztq6EYnV"
      },
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        self.fc1 = nn.Linear(3136, 1000)\n",
        "        self.fc2 = nn.Linear(1000, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        # print(out.shape)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3714Y8uHiYbV"
      },
      "source": [
        "class AlexNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AlexNet, self).__init__()\n",
        "        # input 1*28*28\n",
        "        self.conv1 = nn.Conv2d(1, 96, kernel_size=11, stride=4)\n",
        "        self.conv2 = nn.Conv2d(96, 256, kernel_size=5, padding=2)\n",
        "        self.conv3 = nn.Conv2d(256, 384, kernel_size=3,padding=1)\n",
        "        self.conv4 = nn.Conv2d(384, 384, kernel_size=3,padding=1)\n",
        "        self.conv5 = nn.Conv2d(384, 256, kernel_size=3,padding=1)\n",
        "        self.fc1 = nn.Linear(256*6*6, 4096)\n",
        "        self.fc2 = nn.Linear(4096, 4096)\n",
        "        self.fc3 = nn.Linear(4096, 10)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(torch.relu(self.conv1(x)), kernel_size=3, stride=2) # 96 filters + maxpooling => 96*27*27\n",
        "        x = F.max_pool2d(torch.relu(self.conv2(x)), kernel_size=3, stride=2) # 256 filters + maxpooling => 256*13*13\n",
        "        x = torch.relu(self.conv3(x)) # 384 filters => 384*13*13\n",
        "        x = torch.relu(self.conv4(x)) # 384 filters => 384*13*13\n",
        "        x = F.max_pool2d(torch.relu(self.conv5(x)), kernel_size=3, stride=2) # 256 filters => 256*6*6\n",
        "        x = self.dropout(x) \n",
        "        x = x.view(-1, 256*6*6) \n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return F.softmax(x)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}